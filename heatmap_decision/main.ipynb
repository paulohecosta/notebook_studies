{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcao Lambda com AWS Wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://371716203543-files/target/3b13264c5b9c4e819df9474498dd353b.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "# Define o dtype do DataFrame\n",
    "dtype = {\n",
    "    \"year\": \"int\",\n",
    "    \"industry_code\": \"string\",\n",
    "    \"industry_name\": \"string\",\n",
    "    \"variable\": \"string\"\n",
    "}\n",
    "\n",
    "# Lê o CSV do S3 e cria um DataFrame com o dtype definido\n",
    "df = wr.s3.read_csv(f\"s3://371716203543-files/origin/base.csv\", dtype=dtype)\n",
    "\n",
    "# Escreve o DataFrame no formato Parquet no S3\n",
    "wr.s3.to_parquet(\n",
    "    df=df,\n",
    "    path=f\"s3://371716203543-files/target/\",\n",
    "    filename=\"base.parquet\",\n",
    "    database=database,\n",
    "    table=table,\n",
    "    # Sugestão de melhoria: incluir opção \"partition_cols\" para particionar o Parquet por ano e variável\n",
    "    partition_cols=[\"year\", \"industry_code\"],\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcao Glue com PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Inicializa o SparkContext e o GlueContext\n",
    "print('INIT')\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "\n",
    "print('GLUE CONTEXT LOADED...')\n",
    "\n",
    "# Define o schema do DataFrame\n",
    "schema = StructType (\n",
    "    [\n",
    "        StructField ('year', IntegerType(), True),\n",
    "        StructField ('industry_code', StringType(), True),\n",
    "        StructField ('industry_name', StringType(), True),\n",
    "        StructField ('variable', StringType(), True)\n",
    "    ])\n",
    "\n",
    "# Lê o CSV do S3 e cria um DataFrame\n",
    "df = spark.read.option('mode', 'DROPMALFORMED').option(\"charset\", \"UTF-8\").csv(\"s3://371716203543-files/origin/\", schema=schema)\n",
    "\n",
    "# Converte o DataFrame em um DynamicFrame do Glue\n",
    "dynamicFrame = DynamicFrame.fromDF(df, glueContext, \"nest\")\n",
    "\n",
    "# Exibe o schema e as primeiras linhas do DynamicFrame\n",
    "dynamicFrame.printSchema()\n",
    "dynamicFrame.toDF().show(5)\n",
    "\n",
    "# Define opções adicionais para escrita no Glue Catalog\n",
    "additionalOptions = {\"enableUpdateCatalog\": True}\n",
    "\n",
    "# Escreve o DynamicFrame no Glue Catalog como tabela \"dump_table\" no database \"dump_base\"\n",
    "sink = glueContext.write_dynamic_frame_from_catalog(frame=dynamicFrame, database=\"dump_base\",\n",
    "                                                    table_name=\"dump_table\", transformation_ctx=\"write_sink\",\n",
    "                                                    additional_options=additionalOptions)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
